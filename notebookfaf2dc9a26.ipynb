{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torchtext\nfrom torchtext.data.utils import get_tokenizer\nfrom collections import Counter\nfrom torchtext.vocab import vocab\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import DataLoader\nimport random\nfrom typing import Tuple\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch import Tensor\nimport math\nimport time","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-23T19:14:45.004689Z","iopub.execute_input":"2022-11-23T19:14:45.005497Z","iopub.status.idle":"2022-11-23T19:14:48.112839Z","shell.execute_reply.started":"2022-11-23T19:14:45.005403Z","shell.execute_reply":"2022-11-23T19:14:48.111227Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"main_df = pd.read_csv('/kaggle/input/feedback-prize-english-language-learning/train.csv')\n","metadata":{"execution":{"iopub.status.busy":"2022-11-23T19:14:48.115535Z","iopub.execute_input":"2022-11-23T19:14:48.116516Z","iopub.status.idle":"2022-11-23T19:14:48.387341Z","shell.execute_reply.started":"2022-11-23T19:14:48.116449Z","shell.execute_reply":"2022-11-23T19:14:48.386489Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/feedback-prize-english-language-learning/test.csv')\ntest_df['cohesion'] = 1.0\ntest_df['syntax'] = 1.0\ntest_df['vocabulary'] = 1.0 \ntest_df['phraseology'] = 1.0 \ntest_df['grammar'] = 1.0\ntest_df['conventions'] = 1.0 ","metadata":{"execution":{"iopub.status.busy":"2022-11-23T19:14:48.388541Z","iopub.execute_input":"2022-11-23T19:14:48.389015Z","iopub.status.idle":"2022-11-23T19:14:48.413917Z","shell.execute_reply.started":"2022-11-23T19:14:48.388985Z","shell.execute_reply":"2022-11-23T19:14:48.412856Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_df, val_df = train_test_split(main_df, test_size=0.03, random_state=6)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T19:14:48.417768Z","iopub.execute_input":"2022-11-23T19:14:48.418094Z","iopub.status.idle":"2022-11-23T19:14:48.428559Z","shell.execute_reply.started":"2022-11-23T19:14:48.418062Z","shell.execute_reply":"2022-11-23T19:14:48.427277Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"tokenizer = get_tokenizer('spacy', language='en')\nMAX_SENT_LEN = 1000\n\ndef mark_bos_eos(text):\n    final_text = ''\n    final_text = final_text.strip()\n    l = text.split('.')[:-1]\n    for sentence in l:\n        final_text = final_text + ' <bos> ' + sentence + ' <eos> '\n    final_text = final_text.replace('  ', ' ')\n    final_text = final_text.strip()\n    \n    return final_text\n\ndef pad_sequence(tok_seq, pad_tok, max_len=1000):\n    cur_len = len(tok_seq)\n    if cur_len >= max_len:\n        return tok_seq[:max_len]\n\n    padding = [pad_tok]*(max_len - cur_len)\n    text = tok_seq + padding\n    \n    return text\n\ndef build_vocab(df, tokenizer):\n    counter = Counter()\n    df['full_text'].apply(lambda string_ : counter.update(tokenizer(string_)))\n    \n    return vocab(counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n\nvocab_ = build_vocab(train_df, tokenizer)\nvocab_.set_default_index(vocab_['<unk>'])\n\ndef data_process(df):\n    data = []\n    df['full_text_'] = df['full_text'].apply(lambda text : mark_bos_eos(text))\n    for raw_en, label in zip(df['full_text_'], df[['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']].values.tolist()):\n        tokens = [vocab_[token] for token in tokenizer(raw_en)]\n        token_seq = pad_sequence(tokens, vocab_['<pad>'], MAX_SENT_LEN)\n        data.append((token_seq, label))\n        \n    return data\n\ntrain_data = data_process(train_df)\nval_data = data_process(val_df)\ntest_data = data_process(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T19:14:48.432626Z","iopub.execute_input":"2022-11-23T19:14:48.433522Z","iopub.status.idle":"2022-11-23T19:15:08.218227Z","shell.execute_reply.started":"2022-11-23T19:14:48.433449Z","shell.execute_reply":"2022-11-23T19:15:08.216987Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torchtext/data/utils.py:123: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n  warnings.warn(f'Spacy model \"{language}\" could not be loaded, trying \"{OLD_MODEL_SHORTCUTS[language]}\" instead')\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\n\nBATCH_SIZE = 128\nPAD_IDX = vocab_['<pad>']\nBOS_IDX = vocab_['<bos>']\nEOS_IDX = vocab_['<eos>']\n\ndef generate_batch(data_batch):\n    en_batch = []\n    label_batch = []\n    \n    for (en_item, label_item) in data_batch:\n        en_batch.append(en_item)\n        label_batch.append(label_item)\n    \n    en_batch = torch.tensor(en_batch, dtype=torch.long)\n    label_batch = torch.tensor(label_batch, dtype=torch.float)\n    \n    return en_batch, label_batch\n\ndef generate_batch2(data_batch):\n    en_batch = []\n    label_batch = []\n    \n    for (en_item, label_item) in data_batch:\n        en_batch.append(en_item)\n        label_batch.append(label_item)\n    \n    en_batch = torch.tensor(en_batch, dtype=torch.float)\n    label_batch = torch.tensor(label_batch, dtype=torch.float)\n    \n    return en_batch, label_batch\n\ntrain_iter = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch)\nvalid_iter = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch)\ntest_iter = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-23T19:32:34.744636Z","iopub.execute_input":"2022-11-23T19:32:34.745022Z","iopub.status.idle":"2022-11-23T19:32:34.756622Z","shell.execute_reply.started":"2022-11-23T19:32:34.744990Z","shell.execute_reply":"2022-11-23T19:32:34.755514Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"cpu\n","output_type":"stream"}]},{"cell_type":"code","source":"class MODEL(nn.Module):\n    def __init__(self,\n                 input_dim: int,\n                 emb_dim: int,\n                 enc_hid_dim: int,\n                 out_dim: int,\n                 dropout: float):\n        super().__init__()\n        \n        self.input_dim = input_dim\n        self.emb_dim = emb_dim\n        self.enc_hid_dim = enc_hid_dim\n        self.out_dim = out_dim\n        self.dropout = dropout\n        \n        self.embedding = nn.Embedding(input_dim, emb_dim)\n        \n        self.lstm = nn.LSTM(emb_dim, enc_hid_dim, num_layers=1, bidirectional=False, batch_first=True, dropout=dropout)\n        \n        self.fc = nn.Linear(MAX_SENT_LEN * enc_hid_dim, out_dim)\n        \n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, src: Tensor) -> Tuple[Tensor]:\n        \n        embedded = self.dropout(self.embedding(src))\n        \n        outputs, _ = self.lstm(embedded)\n        \n        outputs = torch.reshape(outputs, (outputs.shape[0], outputs.shape[1]*outputs.shape[2]))\n        \n        fc_out = self.fc(outputs)\n        \n        return fc_out\n    ","metadata":{"execution":{"iopub.status.busy":"2022-11-23T19:32:38.193701Z","iopub.execute_input":"2022-11-23T19:32:38.194443Z","iopub.status.idle":"2022-11-23T19:32:38.204196Z","shell.execute_reply.started":"2022-11-23T19:32:38.194405Z","shell.execute_reply":"2022-11-23T19:32:38.203097Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"INPUT_DIM = len(vocab_)\nEMB_DIM = 256\nGRU_HID_DIM = 128\nOUTPUT_DIM = 6\nDROPOUT = 0.2\n","metadata":{"execution":{"iopub.status.busy":"2022-11-23T19:32:40.461149Z","iopub.execute_input":"2022-11-23T19:32:40.461542Z","iopub.status.idle":"2022-11-23T19:32:40.466633Z","shell.execute_reply.started":"2022-11-23T19:32:40.461495Z","shell.execute_reply":"2022-11-23T19:32:40.465680Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model = MODEL(INPUT_DIM, EMB_DIM, GRU_HID_DIM, OUTPUT_DIM, DROPOUT)\nmodel.to(device)\n\ndef init_weights(m: nn.Module):\n    for name, param in m.named_parameters():\n        if 'weight' in name:\n            nn.init.normal_(param.data, mean=0, std=0.01)\n        else:\n            nn.init.constant_(param.data, 0)\n            \n\nmodel.apply(init_weights)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T19:32:42.248472Z","iopub.execute_input":"2022-11-23T19:32:42.248871Z","iopub.status.idle":"2022-11-23T19:32:42.415628Z","shell.execute_reply.started":"2022-11-23T19:32:42.248837Z","shell.execute_reply":"2022-11-23T19:32:42.414653Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"MODEL(\n  (embedding): Embedding(24777, 256)\n  (lstm): LSTM(256, 128, batch_first=True, dropout=0.2)\n  (fc): Linear(in_features=128000, out_features=6, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"class MCRMSE(nn.Module):\n    def __init__(self, output_dim):\n        super().__init__()\n        self.mse = nn.MSELoss(reduction='sum')\n        self.no_cols = output_dim\n        \n    def forward(self, target, output):\n        rmse = torch.pow(torch.div(self.mse(target, output), output.shape[0]), 0.5)\n        mcrmse = torch.div(rmse, self.no_cols)\n        \n        return mcrmse","metadata":{"execution":{"iopub.status.busy":"2022-11-23T19:32:44.221383Z","iopub.execute_input":"2022-11-23T19:32:44.222019Z","iopub.status.idle":"2022-11-23T19:32:44.228615Z","shell.execute_reply.started":"2022-11-23T19:32:44.221985Z","shell.execute_reply":"2022-11-23T19:32:44.227391Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"criterion = MCRMSE(OUTPUT_DIM)\n\noptimizer = optim.Adam(model.parameters())\n\ndef count_parameters(model: nn.Module):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f'The model has {count_parameters(model):,} trainable parameters')","metadata":{"execution":{"iopub.status.busy":"2022-11-23T19:32:46.252593Z","iopub.execute_input":"2022-11-23T19:32:46.252977Z","iopub.status.idle":"2022-11-23T19:32:46.260513Z","shell.execute_reply.started":"2022-11-23T19:32:46.252943Z","shell.execute_reply":"2022-11-23T19:32:46.259416Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"The model has 7,308,550 trainable parameters\n","output_type":"stream"}]},{"cell_type":"code","source":"def train(model: nn.Module,\n          iterator: torch.utils.data.DataLoader,\n          optimizer: optim.Optimizer,\n          criterion: nn.Module,\n          clip: float):\n    \n    model.train()\n    \n    epoch_loss = 0\n    \n    for _, (src, trg) in enumerate(iterator):\n        src, trg = src.to(device), trg.to(device)\n        \n        optimizer.zero_grad()\n        \n        output = model(src)\n        \n        loss = criterion(output, trg)\n        \n        loss.backward()\n        \n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n        \n        optimizer.step()\n        \n        epoch_loss += loss.item()\n        \n    return epoch_loss / len(iterator)\n\ndef evaluate(model: nn.Module,\n             iterator: torch.utils.data.DataLoader,\n             criterion: nn.Module):\n    \n    model.eval()\n    \n    epoch_loss = 0\n    \n    with torch.no_grad():\n        \n        for _, (src, trg) in enumerate(iterator):\n            src, trg = src.to(device), trg.to(device)\n            \n            output = model(src)\n            \n            loss = criterion(output, trg)\n            \n            epoch_loss += loss.item()\n    \n    return epoch_loss / len(iterator)\n\ndef epoch_time(start_time: int,\n               end_time: int):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time / 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs\n\nN_EPOCHS = 10\nCLIP = 1\n\nbest_valid_loss = float('inf')\n\nfor epoch in range(N_EPOCHS):\n    \n    start_time = time.time()\n    \n    train_loss = train(model, train_iter, optimizer, criterion, CLIP)\n    valid_loss = evaluate(model, valid_iter, criterion)\n    \n    end_time = time.time()\n    \n    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n    \n    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n    print(f'\\t Val. Loss: {valid_loss:.3f} | Val. PPL: {math.exp(valid_loss):7.3f}')\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-11-23T19:32:48.146772Z","iopub.execute_input":"2022-11-23T19:32:48.147770Z","iopub.status.idle":"2022-11-23T19:47:57.140678Z","shell.execute_reply.started":"2022-11-23T19:32:48.147733Z","shell.execute_reply":"2022-11-23T19:47:57.139557Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Epoch: 01 | Time: 1m 30s\n\tTrain Loss: 0.446 | Train PPL:   1.561\n\t Val. Loss: 0.276 | Val. PPL:   1.318\nEpoch: 02 | Time: 1m 30s\n\tTrain Loss: 0.240 | Train PPL:   1.272\n\t Val. Loss: 0.219 | Val. PPL:   1.245\nEpoch: 03 | Time: 1m 31s\n\tTrain Loss: 0.207 | Train PPL:   1.231\n\t Val. Loss: 0.252 | Val. PPL:   1.287\nEpoch: 04 | Time: 1m 30s\n\tTrain Loss: 0.220 | Train PPL:   1.246\n\t Val. Loss: 0.282 | Val. PPL:   1.326\nEpoch: 05 | Time: 1m 31s\n\tTrain Loss: 0.212 | Train PPL:   1.236\n\t Val. Loss: 0.279 | Val. PPL:   1.322\nEpoch: 06 | Time: 1m 30s\n\tTrain Loss: 0.208 | Train PPL:   1.231\n\t Val. Loss: 0.252 | Val. PPL:   1.287\nEpoch: 07 | Time: 1m 30s\n\tTrain Loss: 0.190 | Train PPL:   1.209\n\t Val. Loss: 0.243 | Val. PPL:   1.275\nEpoch: 08 | Time: 1m 30s\n\tTrain Loss: 0.163 | Train PPL:   1.177\n\t Val. Loss: 0.307 | Val. PPL:   1.360\nEpoch: 09 | Time: 1m 31s\n\tTrain Loss: 0.173 | Train PPL:   1.189\n\t Val. Loss: 0.314 | Val. PPL:   1.369\nEpoch: 10 | Time: 1m 30s\n\tTrain Loss: 0.168 | Train PPL:   1.182\n\t Val. Loss: 0.276 | Val. PPL:   1.318\n","output_type":"stream"}]},{"cell_type":"code","source":"train_output = np.empty((0,6), float)\n\nwith torch.no_grad():\n    for _, (src, trg) in enumerate(train_iter):\n        src, trg = src.to(device), trg.to(device)\n        pred = model(src)\n        pred = pred.to('cpu')\n        train_output = np.append(train_output, pred, axis=0)\n        \ntrain_output = train_output.T\nprint(train_output.shape)\n\ntest_output_mid = np.empty((0,6), float)\n\nwith torch.no_grad():\n    for _, (src, trg) in enumerate(test_iter):\n        src, trg = src.to(device), trg.to(device)\n        pred = model(src)\n        pred = pred.to('cpu')\n        test_output_mid = np.append(test_output_mid, pred, axis=0)\n        \ntest_output_mid = test_output_mid.T\nprint(test_output_mid.shape)\n\nval_output = np.empty((0,6), float)\n\nwith torch.no_grad():\n    for _, (src, trg) in enumerate(valid_iter):\n        src, trg = src.to(device), trg.to(device)\n        pred = model(src)\n        pred = pred.to('cpu')\n        val_output = np.append(val_output, pred, axis=0)\n        \nval_output = val_output.T\nprint(val_output.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T19:30:16.094433Z","iopub.execute_input":"2022-11-23T19:30:16.094941Z","iopub.status.idle":"2022-11-23T19:30:44.070212Z","shell.execute_reply.started":"2022-11-23T19:30:16.094907Z","shell.execute_reply":"2022-11-23T19:30:44.069021Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"(6, 3793)\n(6, 3)\n(6, 118)\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error","metadata":{"execution":{"iopub.status.busy":"2022-11-23T20:35:06.358234Z","iopub.execute_input":"2022-11-23T20:35:06.358717Z","iopub.status.idle":"2022-11-23T20:35:06.364217Z","shell.execute_reply.started":"2022-11-23T20:35:06.358675Z","shell.execute_reply":"2022-11-23T20:35:06.362870Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"def model_result_train(data):\n    models = []\n    data_res = np.array([x[1] for x in data]).T\n    #print(data_res)\n    for i in range(6):\n        rand_arr = (np.random.rand(data_res.shape[1]) * 2) - 1\n        data_sel = np.delete(data_res, i, 0)\n        data_target = data_res[i,:]\n        data_res[i,:] = data_res[i,:] + rand_arr\n        reg = LinearRegression()\n        reg.fit(data_res.T, data_target)\n        models.append(reg)\n    return(models)\n\nmodels = model_result_train(train_data)\ntargets = np.array([x[1] for x in train_data]).T\nmodel_results = train_output.T\ndef model_result_exec(models, model_results, targets):\n    for i in range(6):\n        target = targets[i,:]\n        res = model_results\n        print(target.shape, res[:,i].shape)\n        or_rmse = mean_squared_error(target, res[:, i], squared=False)\n        print(or_rmse)\n        model = models[i]\n        pred = model.predict(res)\n        rmse = mean_squared_error(target, pred, squared=False)\n        print(rmse)\n\nmodel_result_exec(models, model_results, targets)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-23T20:40:34.194451Z","iopub.execute_input":"2022-11-23T20:40:34.194888Z","iopub.status.idle":"2022-11-23T20:40:34.234199Z","shell.execute_reply.started":"2022-11-23T20:40:34.194853Z","shell.execute_reply":"2022-11-23T20:40:34.233046Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stdout","text":"(3793,) (3793,)\n0.8761160652287004\n0.8761160652287012\n(3793,) (3793,)\n0.8742526816911792\n0.8742526816911796\n(3793,) (3793,)\n0.7963907271281019\n0.7963907271281009\n(3793,) (3793,)\n0.9039069913636952\n0.9039069913636955\n(3793,) (3793,)\n1.0369511423012887\n1.0369511423012887\n(3793,) (3793,)\n0.9073516457285837\n0.9073516457285841\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"coh, syn, voc, phr, gra, conv = train_df['cohesion'], train_df['syntax'], train_df['vocabulary'], train_df['phraseology'], train_df['grammar'], train_df['conventions']\ntrain_outputs = []\nfor idx, (c, s, v, p, g, cv) in enumerate(zip(coh, syn, voc, phr, gra, conv)):\n    data = (list(train_output[:,idx]), [c, s, v, p, g, cv])\n    train_outputs.append(data)\n\ncoh, syn, voc, phr, gra, conv = val_df['cohesion'], val_df['syntax'], val_df['vocabulary'], val_df['phraseology'], val_df['grammar'], val_df['conventions']\nval_outputs = []\nfor idx, (c, s, v, p, g, cv) in enumerate(zip(coh, syn, voc, phr, gra, conv)):\n    data = (list(val_output[:,idx]), [c, s, v, p, g, cv])\n    val_outputs.append(data)\n    \ncoh, syn, voc, phr, gra, conv = test_df['cohesion'], test_df['syntax'], test_df['vocabulary'], test_df['phraseology'], test_df['grammar'], test_df['conventions']\ntest_outputs = []\nfor idx, (c, s, v, p, g, cv) in enumerate(zip(coh, syn, voc, phr, gra, conv)):\n    data = (list(test_output_mid[:,idx]), [c, s, v, p, g, cv])\n    test_outputs.append(data)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T19:30:44.074761Z","iopub.execute_input":"2022-11-23T19:30:44.075343Z","iopub.status.idle":"2022-11-23T19:30:44.126129Z","shell.execute_reply.started":"2022-11-23T19:30:44.075298Z","shell.execute_reply":"2022-11-23T19:30:44.124957Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-11-23T19:31:11.465335Z","iopub.execute_input":"2022-11-23T19:31:11.465761Z","iopub.status.idle":"2022-11-23T19:31:11.470960Z","shell.execute_reply.started":"2022-11-23T19:31:11.465724Z","shell.execute_reply":"2022-11-23T19:31:11.470081Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"[([3.2467923164367676, 3.0404694080352783, 3.668672800064087, 3.3395426273345947, 3.252776861190796, 3.1035242080688477], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]), ([2.953334331512451, 2.997270345687866, 3.081468343734741, 2.9999661445617676, 3.074998617172241, 3.1529500484466553], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]), ([3.3455190658569336, 3.01790189743042, 3.626939296722412, 3.644810199737549, 3.4584615230560303, 3.3398725986480713], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0])]\n","output_type":"stream"}]},{"cell_type":"code","source":"submission_df = pd.DataFrame({'text_id':test_df['text_id'], 'cohesion':test_output_final[0],\n                             'syntax': test_output_final[1], 'vocabulary': test_output_final[2],\n                             'phraseology': test_output_final[3], 'grammar': test_output_final[4],\n                             'conventions': test_output_final[5]})\nfor col in submission_df.columns:\n    if col != 'text_id':\n        submission_df[col] = submission_df[col].abs()","metadata":{"execution":{"iopub.status.busy":"2022-11-23T19:30:44.127313Z","iopub.execute_input":"2022-11-23T19:30:44.127769Z","iopub.status.idle":"2022-11-23T19:30:44.485681Z","shell.execute_reply.started":"2022-11-23T19:30:44.127737Z","shell.execute_reply":"2022-11-23T19:30:44.484275Z"},"trusted":true},"execution_count":15,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/3584681167.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m submission_df = pd.DataFrame({'text_id':test_df['text_id'], 'cohesion':test_output_final[0],\n\u001b[0m\u001b[1;32m      2\u001b[0m                              \u001b[0;34m'syntax'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_output_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vocabulary'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_output_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                              \u001b[0;34m'phraseology'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_output_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'grammar'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_output_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                              'conventions': test_output_final[5]})\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubmission_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'test_output_final' is not defined"],"ename":"NameError","evalue":"name 'test_output_final' is not defined","output_type":"error"}]},{"cell_type":"code","source":"print(submission_df)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T19:30:44.486494Z","iopub.status.idle":"2022-11-23T19:30:44.486937Z","shell.execute_reply.started":"2022-11-23T19:30:44.486741Z","shell.execute_reply":"2022-11-23T19:30:44.486761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T19:30:44.488370Z","iopub.status.idle":"2022-11-23T19:30:44.488797Z","shell.execute_reply.started":"2022-11-23T19:30:44.488595Z","shell.execute_reply":"2022-11-23T19:30:44.488615Z"},"trusted":true},"execution_count":null,"outputs":[]}]}